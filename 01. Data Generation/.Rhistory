# Imports
library(readtext)
# Cleaning environment data
rm(list = ls())
# Working directory
setwd('/Users/yeqiaoling/Desktop/Singularity_take_home/text-document-classifer/01. Data Generation')
# Path of the raw training data
path <- '/Users/yeqiaoling/Desktop/Singularity_take_home/text-document-classifer/00. Raw Data/train'
# List with the 20 classes
list_categories <- list.files(path=path)
# Check the number of files in each category folder
summary_categories <- data.frame(matrix(ncol = 2, nrow = 0))
colnames(summary_categories) <- c('Category', 'Number_of_Files')
for (category in list_categories){
category_path <- paste(path, category, sep='/')
n_files <- length(list.files(path = category_path))
summary_categories <- rbind(summary_categories, data.frame('Category' = category, 'Number_of_Files' = n_files))
}
summary_categories
172*3
median(summary_categories$Number_of_Files)
min(summary_categories$Number_of_Files)
boxplot(summary_categories$Number_of_Files)
sort(summary_categories$Number_of_Files)
summary(summary_categories$Number_of_Files)
six_number_summary <- summary(summary_categories$Number_of_Files)
six_number_summary[3]
lower_bound <- six_number_summary[3] - 1.5 * (six_number_summary[5] - six_number_summary[2])
lower_bound
upper_bound <- six_number_summary[3] + 1.5 * (six_number_summary[5] - six_number_summary[2])
IQR <- six_number_summary[5] - six_number_summary[2]
lower_bound <- six_number_summary[3] - 1.5 * IQR
upper_bound <- six_number_summary[3] + 1.5 * IQR
summary_categories$Number_of_Files < lower_bound
quantile(nof)
# re-sample imbalanced data, i.e., change number of files per category
nof <- summary_categories$Number_of_Files
quantile(nof)
?quantile
IQR <- quantile(nof, prob = 0.75) - quantile(nof, prob = 0.25)
IQR
lower_bound <- quantile(nof, prob = 0.5) - 1.5 * IQR
lower_bound
upper_bound
upper_bound <- quantile(nof, prob = 0.5) + 1.5 * IQR
upper_bound
IQR <- quantile(nof, prob = 0.75, names = F) - quantile(nof, prob = 0.25, names = F)
lower_bound <- quantile(nof, prob = 0.5, names = F) - 1.5 * IQR
upper_bound <- quantile(nof, prob = 0.5, names = F) + 1.5 * IQR
upper_bound
nof < lower_bound
which(nof < lower_bound)
nof
under_sample_index <- which(nof < lower_bound)
under_sample_index <- which(nof < lower_bound)
over_sample_index <- which(nof > upper_bound)
over_sample_index
nof[under_sample_index]
lower_bound - nof[under_sample_index]
ceil(lower_bound - nof[under_sample_index])
int(lower_bound - nof[under_sample_index])
floor(lower_bound - nof[under_sample_index])
ceiling(lower_bound - nof[under_sample_index])
under_sample_size <- ceiling(lower_bound - nof[under_sample_index])
over_sample_size <- floor(nof[over_sample_index] - upper_bound)
over_sample_size
nof[over_sample_index] - upper_bound
over_sample_size <- ceiling(nof[over_sample_index] - upper_bound)
over_sample_size
under_sample_index
i=1
sample(nof[i], under_sample_index, replace = T)
nof[i]
?sample
sample(1:nof[i], under_sample_size, replace = T)
sample_index <- list()
for (i in under_sample_index) {
sample_index[[i]] <- sample(1:nof[i], under_sample_size, replace = T)
}
sample_index
samples <- sample(1:nof[i], under_sample_size, replace = T)
samples
sort(sample(1:nof[i], under_sample_size, replace = T))
for (i in under_sample_index) {
sample_indices[[i]] <- sort(sample(1:nof[i], under_sample_size, replace = T))
}
sample_indices <- list()
for (i in c(under_sample_index, over_sample_size)) {
sample_indices[[i]] <- sort(sample(1:nof[i], under_sample_size, replace = T))
}
i
for (i in c(under_sample_index, over_sample_index)) {
sample_indices[[i]] <- sort(sample(1:nof[i], under_sample_size, replace = T))
}
sample_indices
# Read every folder and create the final dataframe in the formaat of (ID, text, category)
df_final <- data.frame(matrix(ncol = 3, nrow = 0))
colnames(df_final) <- c('doc_id', 'text', 'category')
category
path
?readtext
# Working directory
setwd('C:/Users/migue/Data Science/Master Data Science/KSCHOOL/9. TFM/0. Latest News Classifier/01. Dataset Creation')
path_old <- '/Users/yeqiaoling/Desktop/Singularity_take_home/Latest-News-Classifier-nusfdu/0. Latest News Classifier/00. Raw dataset/BBC/bbc-fulltext/bbc'
category_path <- paste(path_old, category, sep='/')
df <- readtext(category_path)
category = 'business'
category_path <- paste(path_old, category, sep='/')
df <- readtext(category_path)
df
for(category in list_categories){
category_path <- paste(path, category, sep='/')
df <- readtext(category_path)
df["category"] <- category
df_final <- rbind(df_final, df)
}
colnames(df_final) <- c('File_Name', 'Content', 'Category')
warnings()
df_final <-
df_final %>%
mutate(Complete_Filename = paste(File_Name, Category, sep='-'))
library(dplyr)
df_final <-
df_final %>%
mutate(Complete_Filename = paste(File_Name, Category, sep='-'))
df_final
getwd()
# Working directory
setwd('/Users/yeqiaoling/Desktop/Singularity_take_home/text-document-classifer/01. Data Generation')
# Save dataset: .rda
save(df_final, file='Dataset.rda')
# Load dataset
load(file='Dataset.rda')
# Write csv to import to python
write.csv2(df_final,fileEncoding = 'utf8', "channels_dataset.csv", row.names = FALSE)
#################################################################################################
# 01. DATASET CREATION
# The aim of this script is to create a dataset with the following information:
#   - Name of the article
#   - Content of the article
#   - Category of the article
#################################################################################################
# Installs
# install.packages("readtext", dependencies=T)
# Imports
library(readtext)
library(dplyr)
# Cleaning environment data
rm(list = ls())
# Working directory
setwd('/Users/yeqiaoling/Desktop/Singularity_take_home/text-document-classifer/01. Data Generation')
# Path of the raw data
TRAIN <- FALSE
if (TRAIN) {
path <- '/Users/yeqiaoling/Desktop/Singularity_take_home/text-document-classifer/00. Raw Data/train'
csv_name <- 'train_dataset.csv'
rda_name <- 'train_dataset.rda'
} else {
path <- '/Users/yeqiaoling/Desktop/Singularity_take_home/text-document-classifer/00. Raw Data/test'
csv_name <- 'test_dataset.csv'
rda_name <- 'test_dataset.rda'
}
# List with the 20 classes
list_categories <- list.files(path = path)
# Check the number of files in each category folder
summary_categories <- data.frame(matrix(ncol = 2, nrow = 0))
colnames(summary_categories) <- c('Category', 'Number_of_Files')
for (category in list_categories){
category_path <- paste(path, category, sep = '/')
n_files <- length(list.files(path = category_path))
summary_categories <- rbind(summary_categories,
data.frame('Category' = category,
'Number_of_Files' = n_files))
}
summary_categories
# re-sample imbalanced data, i.e., change number of files per category
nof <- summary_categories$Number_of_Files
boxplot(nof)
IQR <- quantile(nof, prob = 0.75, names = F) - quantile(nof, prob = 0.25, names = F)
lower_bound <- quantile(nof, prob = 0.5, names = F) - 1.5 * IQR
upper_bound <- quantile(nof, prob = 0.5, names = F) + 1.5 * IQR
under_sample_index <- which(nof < lower_bound)
over_sample_index <- which(nof > upper_bound)
under_sample_size <- ceiling(lower_bound - nof[under_sample_index])
over_sample_size <- ceiling(nof[over_sample_index] - upper_bound)
sample_indices <- list()
for (i in c(under_sample_index, over_sample_index)) {
sample_indices[[i]] <- sort(sample(1:nof[i], under_sample_size, replace = T))
}
# Read every folder and create the final dataframe in the formaat of (ID, text, category)
df_final <- data.frame(matrix(ncol = 3, nrow = 0))
colnames(df_final) <- c('doc_id', 'text', 'category')
for(category in list_categories){
category_path <- paste(path, category, sep='/')
df <- readtext(category_path)
df["category"] <- category
df_final <- rbind(df_final, df)
}
colnames(df_final) <- c('File_Name', 'Content', 'Category')
df_final <-
df_final %>% s
mutate(Complete_Filename = paste(File_Name, Category, sep='-'))
# Save dataset: .rda
save(df_final, file = rda_name)
# Load dataset
load(file = rda_name)
# Write csv to import to python
write.csv2(df_final,fileEncoding = 'utf8', csv_name, row.names = FALSE)
head(df_final)
